{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, concatenate, Conv2D, ZeroPadding2D, BatchNormalization, Flatten, Conv2DTranspose\n",
    "from tensorflow.keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, Lambda\n",
    "from tensorflow.keras.layers import add, concatenate, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import History\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import skimage\n",
    "from skimage import img_as_ubyte, img_as_float32, img_as_uint\n",
    "import skimage.transform\n",
    "from skimage.transform import resize\n",
    "import skimage.io\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images, imsave\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage import io\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.morphology import label, ball, disk, dilation, binary_erosion, remove_small_objects, erosion, closing, reconstruction, binary_closing\n",
    "from skimage.measure import label,regionprops, perimeter\n",
    "from skimage.morphology import binary_dilation, binary_opening\n",
    "from skimage.filters import roberts, sobel\n",
    "from skimage import measure, feature\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage import data\n",
    "from skimage.io import imread\n",
    "import scipy.misc\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    imgs_train = np.load('imgs_train.npy')\n",
    "    masks_train = np.load('masks_train.npy')\n",
    "    return imgs_train, masks_train\n",
    "\n",
    "def load_test_data():\n",
    "    imgs_test = np.load('imgs_test.npy')\n",
    "    return imgs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = int(512/2)\n",
    "img_cols = int(512/2)\n",
    "smooth = 1e-5\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n",
    "\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(K.abs(y_true_f * y_pred_f))\n",
    "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "def jaccard_coef_loss(y_true, y_pred):\n",
    "  return 1-jaccard_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 UNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "\n",
    "def get_unet():\n",
    "    inputs = Input((img_rows, img_cols, 1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Dropout(0.15)(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Dropout(0.15)(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Dropout(0.15)(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Dropout(0.15)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(pool4)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(up6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(conv6)\n",
    "    conv6 = BatchNormalization()(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(up7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(conv7)\n",
    "    conv7 = BatchNormalization()(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(up8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(up9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(conv9)\n",
    "    conv9 = BatchNormalization()(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid', kernel_regularizer=regularizers.l2(1e-4))(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Nadam(lr = 2e-4), loss=dice_coef_loss, metrics=[dice_coef]) # Adam(learning_rate=1e-3)\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_unet2():\n",
    "    inputs = Input((img_rows, img_cols, 1))\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(inputs)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Dropout(0.15)(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Dropout(0.15)(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(1e-4))(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "\n",
    "    # Decoder\n",
    "    up4 = concatenate([UpSampling2D(size=(2, 2))(conv3), conv2], axis=-1)\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(up4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "\n",
    "    up5 = concatenate([UpSampling2D(size=(2, 2))(conv4), conv1], axis=-1)\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(up5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5)\n",
    "    conv5 = BatchNormalization()(conv5)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv5)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3), loss=dice_coef_loss, metrics=[dice_coef]) # Adam(learning_rate=1e-3)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.applications.vgg16 import *\n",
    "\n",
    "def fcn():\n",
    "    ch_out = 1\n",
    "    inputs = Input((img_rows, img_cols, 1))\n",
    "    expanded_inputs = Concatenate()([inputs, inputs, inputs])\n",
    "\n",
    "    # Building a pre-trained VGG-16 feature extractor (i.e., without the final FC layers)\n",
    "    vgg16 = VGG16(include_top=False, weights='imagenet', input_tensor=expanded_inputs)\n",
    "    # Recovering the feature maps generated by each of the 3 final blocks:\n",
    "    f3 = vgg16.get_layer('block3_pool').output\n",
    "    f4 = vgg16.get_layer('block4_pool').output\n",
    "    f5 = vgg16.get_layer('block5_pool').output\n",
    "\n",
    "    # Replacing VGG dense layers by convolutions:\n",
    "    f5_conv1 = Conv2D(filters=4086, kernel_size=7, padding='same',\n",
    "                      activation='relu', kernel_regularizer=regularizers.l2(1e-4))(f5)\n",
    "    f5_drop1 = Dropout(0.5)(f5_conv1)\n",
    "    f5_conv2 = Conv2D(filters=4086, kernel_size=1, padding='same',\n",
    "                      activation='relu', kernel_regularizer=regularizers.l2(1e-4))(f5_drop1)\n",
    "    f5_drop2 = Dropout(0.5)(f5_conv2)\n",
    "    f5_conv3 = Conv2D(filters=ch_out, kernel_size=1, padding='same',\n",
    "                      activation=None, kernel_regularizer=regularizers.l2(1e-4))(f5_drop2)\n",
    "\n",
    "\n",
    "    # Using a transposed conv (w/ s=2) to upscale `f5` into a 14 x 14 map\n",
    "    # so it can be merged with features from `f4_conv1` obtained from `f4`:\n",
    "    f5_conv3_x2 = Conv2DTranspose(filters=ch_out, kernel_size=4, strides=2,\n",
    "                                use_bias=False, padding='same', activation='relu')(f5)\n",
    "    f4_conv1 = Conv2D(filters=ch_out, kernel_size=1, padding='same',\n",
    "                      activation=None, kernel_regularizer=regularizers.l2(1e-4))(f4)\n",
    "\n",
    "    # Merging the 2 feature maps (addition):\n",
    "    merge1 = add([f4_conv1, f5_conv3_x2])\n",
    "\n",
    "    # We repeat the operation to merge `merge1` and `f3` into a 28 x 28 map:\n",
    "    merge1_x2 = Conv2DTranspose(filters=ch_out, kernel_size=4, strides=2,\n",
    "                                use_bias=False, padding='same', activation='relu')(merge1)\n",
    "    f3_conv1 = Conv2D(filters=ch_out, kernel_size=1, padding='same',\n",
    "                      activation=None, kernel_regularizer=regularizers.l2(1e-4))(f3)\n",
    "    merge2 = add([f3_conv1, merge1_x2])\n",
    "\n",
    "    # Finally, we use another transposed conv to decode and up-scale the feature map\n",
    "    # to the original shape, i.e., using a stride 8 to go from 28 x 28 to 224 x 224 here:\n",
    "    outputs = Conv2DTranspose(filters=ch_out, kernel_size=16, strides=8,\n",
    "                              padding='same', activation=None)(merge2)\n",
    "\n",
    "    fcn_model = Model(inputs, outputs)\n",
    "\n",
    "    fcn_model.compile(optimizer=Adam(learning_rate=1e-3), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return fcn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2-D VNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D,PReLU,Conv2DTranspose,add,concatenate,Input,Dropout,BatchNormalization,Activation\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "def resBlock(conv,stage,keep_prob,stage_num=5):#收缩路径\n",
    "    inputs=conv\n",
    "\n",
    "    for _ in range(3 if stage>3 else stage):\n",
    "        conv=PReLU()(BatchNormalization()(Conv2D(16*(2**(stage-1)), 5, activation = None, padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=regularizers.l2(1e-4))(conv)))\n",
    "        \n",
    "    conv_add=PReLU()(add([inputs,conv]))\n",
    "    conv_drop=Dropout(keep_prob)(conv_add)\n",
    "\n",
    "    if stage<stage_num:\n",
    "        conv_downsample=PReLU()(BatchNormalization()(Conv2D(16*(2**stage), 2, strides=(2, 2),activation = None, padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=regularizers.l2(1e-4))(conv_drop)))\n",
    "        return conv_downsample,conv_add\n",
    "    else:\n",
    "        return conv_add,conv_add\n",
    "\n",
    "def up_resBlock(forward_conv,input_conv,stage):\n",
    "\n",
    "    conv=concatenate([forward_conv,input_conv],axis = -1)\n",
    "    print('conv_concatenate:',conv.get_shape().as_list())\n",
    "    for _ in range(3 if stage>3 else stage):\n",
    "        conv=PReLU()(BatchNormalization()(Conv2D(16*(2**(stage-1)), 5, activation = None, padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=regularizers.l2(1e-4))(conv)))\n",
    "        print('conv_up_stage_%d:' %stage,conv.get_shape().as_list())\n",
    "    conv_add=PReLU()(add([input_conv,conv]))\n",
    "    if stage>1:\n",
    "        conv_upsample=PReLU()(BatchNormalization()(Conv2DTranspose(16*(2**(stage-2)),2,strides=(2, 2),padding='valid',activation = None,kernel_initializer = 'he_normal', kernel_regularizer=regularizers.l2(1e-4))(conv_add)))\n",
    "        return conv_upsample\n",
    "    else:\n",
    "        return conv_add\n",
    "\n",
    "def vnet(pretrained_weights = None,input_size = (256,256,1),num_class=1,is_training=True,stage_num=5,thresh=0.5):\n",
    "    keep_prob = 0.5 if is_training else 1.0 # keep_prob --> dropout\n",
    "    features=[]\n",
    "    input_model = Input(input_size)\n",
    "    x=PReLU()(BatchNormalization()(Conv2D(16, 5, activation = None, padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=regularizers.l2(1e-4))(input_model)))\n",
    "\n",
    "    for s in range(1,stage_num+1):\n",
    "        x,feature=resBlock(x,s,keep_prob,stage_num)\n",
    "        features.append(feature)\n",
    "\n",
    "    conv_up=PReLU()(BatchNormalization()(Conv2DTranspose(16*(2**(s-2)),2,strides=(2, 2),padding='valid',activation = None,kernel_initializer = 'he_normal', kernel_regularizer=regularizers.l2(1e-4))(x)))\n",
    "\n",
    "    for d in range(stage_num-1,0,-1):\n",
    "        conv_up=up_resBlock(features[d-1],conv_up,d)\n",
    "    if num_class>1:\n",
    "        conv_out=Conv2D(num_class, 1, activation = 'softmax', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=regularizers.l2(1e-4))(conv_up)\n",
    "    else:\n",
    "        conv_out=Conv2D(num_class, 1, activation = 'sigmoid', padding = 'same', kernel_initializer = 'he_normal', kernel_regularizer=regularizers.l2(1e-4))(conv_up)\n",
    "\n",
    "    model=Model(inputs=input_model,outputs=conv_out)\n",
    "    print(model.output_shape)\n",
    "\n",
    "    model.compile(optimizer = Nadam(lr = 2e-4), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows = int(512/2)\n",
    "img_cols = int(512/2)\n",
    "\n",
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i], (img_cols, img_rows), preserve_range=True)\n",
    "\n",
    "    imgs_p = imgs_p[..., np.newaxis]\n",
    "    return imgs_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.core.util\n",
    "\n",
    "def ignore_warnings(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "imageio.core.util._precision_warn = ignore_warnings\n",
    "\n",
    "print('-'*30)\n",
    "print('Loading and preprocessing train data...')\n",
    "print('-'*30)\n",
    "imgs_train, imgs_mask_train = load_train_data()\n",
    "\n",
    "imgs_train = preprocess(imgs_train)\n",
    "imgs_mask_train = preprocess(imgs_mask_train)\n",
    "\n",
    "imgs_train = imgs_train.astype('float32')\n",
    "imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "\n",
    "print('-'*30)\n",
    "print('Creating and compiling model...')\n",
    "print('-'*30)\n",
    "model = vnet() # CALL MODEL\n",
    "model_checkpoint = ModelCheckpoint('weights_vnet.h5', monitor='val_loss', save_best_only=True, save_freq='epoch')\n",
    "\n",
    "print('-'*30)\n",
    "print('Fitting model...')\n",
    "print('-'*30)\n",
    "history=model.fit(imgs_train, imgs_mask_train, batch_size=1, epochs=30, verbose=1, shuffle=True,\n",
    "            validation_split=0.3,\n",
    "            callbacks=[model_checkpoint])\n",
    "\n",
    "print('-'*30)\n",
    "print('Loading and preprocessing test data...')\n",
    "print('-'*30)\n",
    "\n",
    "imgs_test = load_test_data()\n",
    "imgs_test = preprocess(imgs_test)\n",
    "imgs_test = imgs_test.astype('float32')\n",
    "\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading saved weights...')\n",
    "print('-'*30)\n",
    "model = get_unet() # get_unet()\n",
    "model.load_weights('YOUR_MODEL_WEIGHT_PATH')\n",
    "\n",
    "model_vnet = vnet()\n",
    "model_vnet.load_weights('YOUR_MODEL_WEIGHT_PATH')\n",
    "\n",
    "print('-'*30)\n",
    "print('Predicting masks on test data...')\n",
    "print('-'*30)\n",
    "imgs_mask_test = model.predict(imgs_train, verbose=1) # imgs_test\n",
    "imgs_mask_test_vnet = model_vnet.predict(imgs_train, verbose=1)\n",
    "\n",
    "np.save('/media/kursat/TOSHIBA EXT5/projects/ANN_PROJE/imgs_mask_test_trainData.npy', imgs_mask_test)\n",
    "np.save('/media/kursat/TOSHIBA EXT5/projects/ANN_PROJE/imgs_mask_test_trainData_vnet.npy', imgs_mask_test_vnet)\n",
    "print('-' * 30)\n",
    "print('Saving predicted masks to files...')\n",
    "print('-' * 30)\n",
    "\n",
    "imgs_test_vnet = model_vnet.predict(imgs_test, verbose=1)\n",
    "np.save('/media/kursat/TOSHIBA EXT5/projects/ANN_PROJE/imgs_test_vnet.npy', imgs_test_vnet)\n",
    "print('-' * 30)\n",
    "print('Saving predicted masks to files (test data)...')\n",
    "print('-' * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train data\n",
    "\"\"\"\n",
    "\n",
    "train_data = np.load('YOUR_TRAIN_DATA_PATH')\n",
    "ground_truth = np.load('YOUR_MASK_DATA_PATH')\n",
    "prediction = np.load('YOUR_PREVIOUS_PREDICTION_DATA_PATH')\n",
    "prediction_vnet = np.load('YOUR_PREDICTION_DATA_PATH')\n",
    "\n",
    "channel = 452 # write any number\n",
    "\n",
    "plt.subplot(141)\n",
    "plt.imshow(train_data[channel, :, :], cmap='gray')\n",
    "plt.title(\"Train Data\")\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.imshow(ground_truth[channel, :, :], cmap='gray')\n",
    "plt.title(\"Ground Truth\")\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.imshow(prediction[channel, :, :], cmap='gray')\n",
    "plt.title(\"Initial Result: UNet\", fontsize=10)\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.imshow(prediction_vnet[channel, :, :], cmap='gray')\n",
    "plt.title(\"Third Report: VNet\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test Data\n",
    "\"\"\"\n",
    "\n",
    "test_data = np.load('YOUR_TEST_DATA_PATH')\n",
    "prediction = np.load('OUR_PREVIOUS_PREDICTION_TEST_DATA_PATH')\n",
    "prediction_vnet = np.load('YOUR_PREDICTION_TEST_DATA_PATH')\n",
    "\n",
    "channel = 115 # write any number\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.imshow(test_data[channel, :, :], cmap='gray')\n",
    "plt.title(\"Test Data\")\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(prediction[channel, :, :], cmap='gray')\n",
    "plt.title(\"Initial Result: UNet\", fontsize=10)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(prediction_vnet[channel, :, :], cmap='gray')\n",
    "plt.title(\"Third Report: VNet\", fontsize=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
